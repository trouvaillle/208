---
layout: post
title:  "12. 데이터 시스템의 미래 - Section 1, 2"
date:   2024-12-19 00:00:00 +0900
categories: study books data-intensive-applications
author: 유석모
announced_on: 2024년 12월 19일
---

<img src="{{ "/assets/img/study/books/data-intensive-applications/chapter12/section1-2/intro.png" | relative_url }}" alt="image" width="480px"/>

마지막 장에서는 데이터 시스템이 미래에 어떻게 변화해야 하는지 설명한다.

상기하자면 이 책의 목적은 애플리케이션과 시스템을 신뢰할 수 있고 확장 가능하며 유지보수하기 쉽게 만드는 방법을 탐구하는 것이다.

- 신뢰성: 내결함성 알고리즘
- 확장성: 파티셔닝
- 유지보수성: 진화와 추상화 메커니즘

현재보다 나은, 견고하고 정확하며 발전 가능한 애플리케이션을 설계하는 방법을 발견하고자한다.

<br/>

## 데이터 통합 <small class="weak">Data Integration</small>

어떤 문제에 대한 몇 가지 해결책을 놓고 트레이드오프에 대해 설명하는 게 책의 주요 주제였다.

데이터를 사용하는 **모든** 상황에 적합한 소프트웨어가 있을 가능성은 낮다.

원하는 애플리케이션 기능을 제공하기 위해서는 반드시 여러 다른 소프트웨어를 함께 엮어 사용해야 한다.

<br/>


### 파생 데이터에 특화된 도구의 결합 <small class="weak">Combining Specialized Tools by Deriving Data</small>

예를 들어 OLTP 데이터베이스와 전문 검색 색인을 통합하는 요구는 일반적이다.

PostreSQL은 간단한 애플리케이션을 만들기에 충분하지만 복잡한 검색 용도로는 불완전하다.

검색 색인은 전문적인 정보 탐색에 유용하지만 일반적인 레코드 시스템으로는 부적합하다.

이와 같은 예와 같이 데이터를 다른 방식으로 표현하는 수가 늘어날수록 데이터 시스템을 통합하기 더욱 어렵다.

DB, 검색 색인, OLAP, 캐시, 머신러닝이나 분류, 랭킹, 추천 시스템으로 데이터를 전달하며 데이터 변화를 기반으로 한 알림을 보내기도 한다.

데이터를 다루는 범위는 어지러울 정도로 넓고 조직 전체 데이터플로를 고려할 필요가 있다.

<br/>

#### 데이터플로에 대한 추론 <small class="weak">Reasoning about dataflows</small>

같은 데이터 사본을 여러 저장소에 유지해야할 때 이벽과 출력을 분명히 할 필요가 있다.

데이터가 처음 기록되는 장소, 원본과 표현형의 파생 관계, 파생 데이터의 저장 장소와 형식 등에 대해 충분히 고려해야 한다.

예를 들면 변경 데이터 캡처(CDC)를 사용해 일관성을 유지할 수 있다.

검색 색인과 다른 데이터베이스를 사용하는 애플리케이션에서 두 곳으로 쓰기 요청을 보낸다면, <br/> 쓰기 충돌이 발생하기 쉽다. 쓰기의 순서를 결정하는 책임을 맡은 곳이 없기 때문이다. <br/>
이는 영구적인 불일치로 이어질 수 있다.

모든 쓰기의 순서를 결정하는 단일 시스템으로 모든 입력을 넣으면 쓰기를 같은 순서로 처리해 파생 데이터를 생성하기 쉬워진다.

이벤트 로그 기반으로 파생 데이터 시스템을 갱신하면 결정적이고 멱등성을 지녀 결함에서 복구하기가 상당히 쉬워진다.

<br/>

#### 파생 데이터 대 분산 트랜잭션 <small class="weak">Derived data versus distributed transactions</small>

서로 다른 데이터 시스템 간 일관성을 유지하는 고전적인 방법은 분산 트랜잭션이다.

파생 데이터와 분산 트랜잭션은 다른 방식으로 유사한 목표를 달성한다.

| 목표 | 분산 트랜젝션 | 파생 데이터(ex. CDC, 이벤트 소싱) |
| -- | -- | -- |
| 순서 결정 | 상호 배타적인 잠금 사용 | 로그 사용 |
| 정확히 한 번 보장 | 원자적 커밋 | 결정적 재시도와 멱등성 기반 |

분산 트랜잭션은 대개 선형성을 지원하지만<br/>
파생 데이터 시스템은 비동기로 갱신되어 동시간 갱신 보장을 하지 않는다.

분산 트랜잭션 프로토콜 중 XA는 결함 대응에 취약하고 성능면에서 나빠서 유용성이 제한적이다.

다른 대체제가 없는 상황에서 **로그 기반 파생 데이터**가 이종 데이터 시스템을 통합하는 가장 유망한 접근법이다.


<br/>

#### 전체 순서화의 제약 <small class="weak">The limits of total ordering</small>

작은 시스템에서 이벤트 로그의 전체 순서를 보장하는 것은 가능하나,<br/>
대규모 또는 큰 작업부하에서는 전체 순서화에 한계가 있다.

- 전체 순서를 위해 대부분 **단일 리더**가 필요하다.<br/>
    처리량이 커지면 **파티셔닝**을 해야하고, 파티션 간의 이벤트 순서는 애매하다.
- **지역적으로 분산된** 데이터 센터들에 서버가 걸쳐있다면 여러 독립된 리더를 지닌다.<br/>
    데이터센터 간의 이벤트 순서는 정해지지 않았다.
- **마이크로서비스** 배포 시 서로 다른 서비스에서 발생한 이벤트엔 정해진 순서가 없다.
- **클라이언트 상태를 유지**하는 경우 서버와 서로 다른 이벤트 순서를 지닐 수 있다.

이러한 전체 순서화는 **전체 순서 브로드캐스트**가 공식 용어이고 이는 합의와 동등하다.

<br/>

#### 인과성 획득을 위한 이벤트 순서화 <small class="weak">Ordering events to capture causality</small>

예를 들어 친구 끊기 후 남은 친구들에게 메시지를 보내는 경우를 생각해보자.

친구 상태와 메시지를 저장하는 곳이 서로 다르다면<br/>
**친구 끊기** 이벤트와 **메시지 보내기** 이벤트 사이의 순서 의존성이 없다.<br/>
인과성을 획득하지 못하면 끊어진 친구에게 메시지를 보낼 가능성이 있다.

이처럼 인과성이 필요한 애플리케이션의 경우 추가적인 고려가 필요하다.

- 논리적 타임스탬프를 사용. 수신자가 잘못된 순서의 이벤트를 처리해야하고 메타데이터를 추가 전다해야한다.
- 읽기를 이벤트로 처리. 읽기가 발생한 이전의 이벤트로부터 인과적 의존성을 가질 수 있다.
- 충돌 해소 알고리즘. 상태를 유지하는데 유용하지만 외부 부수 효과(ex. 알림)가 있다면 도움되지 않는다.


<br/>


### 일괄 처리와 스트림 처리 <small class="weak">Batch and Stream Processing</small>

데이터 통합의 목표는 데이터를 올바른 장소와 형태로 두는 것이다.

일괄 처리자와 스트림 처리자는 이 목표를 달성하기 위한 도구다.

일괄 처리와 스트림 처리의 출력은 파생 데이터셋이다. 이는 검색 색인이나 구체화 뷰, 추천, 집계 지표 등이 있다.

두 처리는 여러 공통 원리가 있지만 근본적인 차이점은 스트림 처리는 끝이 없는 데이터셋 상에서 운영된다는 점이다.

[스파크](https://spark.apache.org/)는 스트림을 마이크로 일괄 처리 단위로 나누어 처리한다. 반면 [아파치 플링크](https://flink.apache.org/)는 스트림 처리 엔진 상에서 일괄 처리를 수행한다. 이론적으로 하나의 유형은 다른 유형 위에서 애뮬레이션할 수 있다. 하지만 마이크로 일괄 처리는 [홉핑 윈도우나 슬라이딩 윈도우](https://learn.microsoft.com/en-us/azure/stream-analytics/stream-analytics-window-functions)를 구현하기에 성능이 좋지 않다.

<br/>

#### 파생 상태 유지 <small class="weak">Maintaining derived state</small>

일괄 처리는 함수형 특징을 가진다.

- 결정적이고
- 출력이 입력에만 의존하며
- 명시적 출력 외에는 다른 부수 효과가 없는 순수 함수를 장려하며
- 입력은 불변으로 간주하고 출력은 추가 전용으로만 사용한다.

스트림 처리도 유사하지만 상태를 관리할 수 있고 내결함성을 지니게 한다.

입력과 출력을 잘 정의한 결정적 함수의 원리는 내결함성에 도움이 되고 조직 내의 데이터플로 추론을 단순화 한다.

이론상으로 파생 데이터 시스템은 트랜잭션 내의 보조 색인을 동기적으로 갱신하는 것처럼 동기식으로 운영할 수 있다.

하지만 비동기 방식을 사용하면 이벤트 로그 기반 시스템을 훨씬 견고하게 만든다.

비동기 방식은 시스템 일부의 결함이 국소적으로 남아있게 해준다.<br/>
반면 분산 틀내잭션은 참여자 일부가 실패하면 어보트로 인해 나머지 시세틈으로 실패가 확산되어 실패가 증폭된다.

보조 색인의 예시에서 복수의 파티션을 쓰기나 읽기 요청을 보내는 것과 다르게<br/>
색인을 비동기 방식으로 유지한다면 파티션 간 통신에서 더욱 신뢰성 있고 확장성이 좋아진다.

<br/>

#### 애플리케이션 발전을 위한 데이터 재처리 <small class="weak">Reprocessing data for application evolution</small>

파생 데이터를 유지할 때 스트림 처리를 이용하면 입력의 변화를 빠르게 파생 뷰에 반영할 수 있다.

일괄 처리를 사용하면 누적된 상당한 양의 과거 데이터를 재처리해 기존 데이터셋을 반영한 새 파생 뷰를 만들 수 있다.

기존 데이터 재처리는 새로운 기능 추가와 변경된 요구사항에 대응하기 좋은 매커니즘이다.

재처리 없이 스키마를 변경하는 작업은 선택적 필드 추가나 새로운 타입의 레코드를 추가하는 것 같은 간단한 작업으로 제한된다. 이는 읽기와 쓰기 스키마 모두에 해당한다.

재처리를 이용하면 완전히 다른 모델로 데이터셋을 재구축할 수 있다.

파생뷰를 사용하면 **점진적**발전이 가능하다.

이전과 새 스키마를 함께 유지해 같은 데이터를 기반으로 두 개의 독립적인 파생 뷰를 만들 수 있다.

읿부 사용자에게 새로운 뷰를 보게 해 테스트를 진행하고 점직적으로 비율을 늘려 결국 기존 뷰를 내릴 수 있다.

점진적 이전의 장점은 쉬운 롤백이다. 되돌릴 수 없는 손상의 위험을 줄여 시스템을 빠르게 개선해나갈 수 있다.

<br/>


#### 람다 아키텍처 <small class="weak">The lambda architecture</small>
**람다 아키텍처**는 일괄 처리와 스트림 처리를 조합한 방벙이다.

핵심 아이디어는 입력 데이터를 불변 이벤트로서 증가하기만 하는 데이터셋에 추가하는 방식으로 기록해야 한다는 것이다.

람다 아키텍처는 두 개의 다른 시스템을 병행해서 운용한다.

스트림 처리자는 이벤트를 소비해 근사 갱신을 뷰에 빠르게 반영한다.

일괄 처리자는 **같은** 이벤트 집합을 소비해 정확한 버전을 파생 뷰에 반영한다.

| 비교 | 스트림 처리 | 일괄 처리 |
| -- | -- | -- |
| 정확도 | 근사 | 정확 |
| 속도 | 빠름 | 느림 |
| 예시 | 스톰 | 하듑 맵리듀스 |

하지만 람다 이키텍처에도 실질적 문제가 있다.

- 일괄 처리와 스트림 처리 양쪽에서 같은 로직을 유지해야하는 상당한 노력이 필요하다. [Summingbird](https://github.com/twitter/summingbird)와 같이 양쪽에서 실행 가능한 연산 추상화 라이브러리가 있지만 디버깅과 튜닝, 운영 상의 복잡성이 여전히 남아있다.
- 스트림과 일괄 처리 파이프라인이 분리된 출력을 생산하기 때문에 소비자가 두 출력을 병합해야 한다. 조인이나 세션화 같은 복잡한 연산이나 출력이 시계열이 아니면 상당히 어려워진다.
- 일괄 처리가 전체 과거 데이터를 재처리하는 방식은 훌륭하지만 비용이 만만치 않다. 증분 일괄 처리가 가능하지만 낙오자 처리 문제나 윈도우 다르기 같은 문제가 발생한다. 그리고 스트림 레이어와 비슷해져 일괄 처리 레이어를 단순하게 유지하려는 목표와 배치된다.

<br/>

#### 일괄 처리와 스트림 처리의 통합 <small class="weak">Unifying batch and stream processing</small>

최근에는 같은 시스템에서 일괄 처리와 스트림 처리 연산을 모두 구현함으로써 람다 아키텍처의 단점을 빼고 장점만 취할 수 있게 하는 작업이 진행되고 있다.

두 처리를 통합하려면 아래 기능들이 필요하다.

- 최근 이벤트 스트림을 다루는 처리 엔진에서 과거 이벤트를 재생하는 능력. 예를 들어 로그 기반 메시지 브로커는 메시지를 재생하는 능력이 있고, 어떤 스트림 처리자는 HDFS 같은 분산 파일 시스템에서 입력을 읽을 수도 있다.
- 스트림 처리자에서 사용되는 정확히 한 번 시맨틱. 결함이 발생하더라도 결함이 없었던 상황과 동일한 출력을 내는 것을 보장한다.
- 처리 시간 기준이 아니라 이벤트 시간 기준으로 윈도우를 처리하는 도구. [Apache Beam](https://beam.apache.org/)은 해당 연산을 API로 제공하고 아파치 플링크나 [구글 클라우드 데이터플로](https://cloud.google.com/products/dataflow) 상에서 구동할 수 있다.

<br/>

## 데이터베이스 언번들링 <small class="weak">Unbundling Databases</small>
추상화 수준에서 보면 데이터베이스, 하둡, 운영체제는 모두 같은 기능을 수행한다.

이는 모두 정보 관리 시스템으로 데이터를 저장하고 처리하며 질의도 한다.

유닉스는 하드웨어를 상당히 얇게 감싼다는 뜻에서 "간단하다."

관계형 데이터베이슨느 잛은 선언형 질의로 강력한 인프라를 활용 가능하다는 뜻으로 "간단하다."

두 접근법은 철학이 다른 것이고 어느 접근법이 더 좋거나 한 게 아니다.

NoSQL은 유닉스의 저수준 추상화 접근법을 분산 OLTP 저장소 분야로 적용하려는 움직임으로 해석할 수 있다.



<br/>

### 데이터 저장소 기술 구성하기 <small class="weak">Composing Data Storage Technologies</small>

설명했던 데이터베이스의 기능과 동작을 요약하면 아래와 같다.

- 보조 색인은 필드 값을 기반으로 레코드를 효율적으로 검색하는 기능이다.
- 구체화 뷰는 질의 결과를 미리 연산한 캐시의 일종이다.
- 복제 로그는 데이터의 복사본을 다른 노드에 최신 상태로 유지하는 기능이다.
- 전문 검색 색인은 텍스트에서 키워드 검색을 가능하게하는 기능으로 일부 RDB는 내장하고 있다.

데이터베이스에 내장된 기능과 일괄 처리와 스트림 처리로 구축하는 파생 데이터 시스템 사이에는 유사점이 있다.
<br/>

#### 색인 생성하기 <small class="weak">Creating an index</small>

관계형 데이터베이스에서 새 색인을 생성하는 `CREATE INDEX`를 실행했을 때<br/>
데이터베이스는 일관된 스냅숏을 스캔해 색인할 필드를 정렬하고 기록한다.<br/>
그 후 일관된 스냅숏을 만든 이후에 실행된 쓰기의 백로그를 처리한다.<br/>
색인 생성을 완료하면 트랜잭션이 테이블에 쓸 때마다 꾸준히 색인에 반영해야 한다.

이는 새 팔로워 복제본을 구축하는 과정과 대단히 비슷하다. 스트림 시스템에서 CDC와도 유사하다.

`CREATE INDEX`를 실행하면 데이터베이스는 기존 데이터셋을 재처리해서 새로운 파생 뷰를 생성한다.

<br/>

#### 모든 것의 메타데이터베이스 <small class="weak">The meta-database of everything</small>

전체 조직의 데이터플로는 거대한 데이터베이스로 바라볼 수 있다.

일괄 처리나 스트림 처리, ETL 처리를 통해 데이터의 장소와 형태를 바꾸어 저장하는 것은 데이터베이스 시스템과 동일하게 동작한다.

서로 다른 저장소와 처리 도구를 하나의 응집된 시스템으로 구성할 수 있는 두 가지 길이 있다.

1. 연합 데이터베이스: 읽기를 통합<br/>
    연합 데이터베이스(federated database) 또는 폴리스토어(polystore) 접근법은 저장소 엔진과 처리 메서드를 통합해 질의하는 인터페이스를 제공한다. 예를 들면 PostgreSQL의 외래 데이터 랩퍼(foreign data wrapper) 기능은 이 유형에 해당한다.

2. 언번들링 데이터베이스: 쓰기를 통합<br/>
    저장소 시스템들을 신뢰성 있게 결합하기 쉽게 만드는 것(CDC나 이벤트 로그 등을 통해)은 데이터베이스의 색인 유지 기능을 다른 기술에 걸친 쓰기를 동기화 할 수 있는 방식으로 언번들링(unbundling)하는 방식과 유사하다.
    언번들링 접근법은 하나만 잘하는 작은 도구를 사용하는 유닉스 전통을 따른다. 이 도구들은 통일된 저수준 API(파이프)를 통해 통신한다.

<br/>

#### 언번들링이 동작하게 만들기 <small class="weak">Making unbundling work</small>

읽기를 통합하는 것보다 쓰기를 통합하는 것이 어렵고 이에 초점을 맞춘다.

쓰기를 동기화하는 전통적인 접근법은 서로 다른 저장소 시스템 간 분산 트랜잭션을 사용하는 것이다.

하지만 멱등성을 기반으로 쓰기를 수행하는 비동기 이벤트 로그를 사용하는 편이 훨씬 더 강력하고 현실적이다.

분산 트랜잭션은 다른 그룹의 사람들이 만든 시스템에 적용할 때 표준 트랜잭션이 없어 통합하기 매우 어렵다.

멱등적 소비자가 사용하는 순서가 정해진 이벤트 로그는 훨씬 단순한 추상화라서 여러 시스템에 걸쳐 구현하기 쉽다.

<br/>

#### 언번들링 대 통합 시스템 <small class="weak">Unbundled versus integrated systems</small>

<br/>

#### 뭐가 빠졌지? <small class="weak">What’s missing?</small>
<br/>


### 데이터플로 주변 애플리케이션 설계 <small class="weak">Designing Applications Around Dataflow</small>

<br/>


#### 파생 함수로서의 애플리케이션 코드 <small class="weak">Application code as a derivation function</small>

<br/>



#### 애플리케이션 코드와 상태의 분리 <small class="weak">Separation of application code and state</small>
오늘날 대부분의 웹 애플리케이션이 상태 비저장 서비스로 배포된다.

이는 원할 때마다 서버를 추가하고 제거하기에 매우 편리하다.

상태는 데이터베이스에 저장한다.

요즘 추세는 상태 관리(데이터 베이스)와 상태 비저장 애플리케이션 로직을 분리한다.

<br/>


#### 데이터플로: 상태 변경과 애플리케이션 코드 간 상호작용 <small class="weak">Dataflow: Interplay between state changes and application code</small>
데이터베이스를 수동적인 변수로 취급하는 대신 상태 변경과 코드 간의 상호작용과 협동에 대해 좀 더 생각해볼 수 있다.

<br/>


#### 스트림 처리자와 서비스 <small class="weak">Stream processors and services</small>

사용자 요청 시 서비스 간 동기 네트워크 요청을 통하는 것보다
스트림 처리를 통해 구독한 데이터를 저장한 로컬 데이터베이스에 질의한느 것이 효율적이다.

<br/>

### 파생 상태 관찰하기 <small class="weak">Observing Derived State</small>

<img src="{{ "/assets/img/study/books/data-intensive-applications/chapter12/section1-2/figure12-1.png" | relative_url }}" alt="image" width="480px"/>

쓰기 경로(write path)와 읽기 경로(read path)에는 트레이드오프 관계가 있다.

<br/>


#### 구체와 뷰와 캐싱 <small class="weak">Materialized views and caching</small>
<br/>


#### 오프라인 대응 가능한 상태 저장 클라이언트 <small class="weak">Stateful, offline-capable clients</small>


<br/>


#### 상태 변경을 클라이언트에게 푸시하기 <small class="weak">Pushing state changes to clients</small>

Sever-Sent Event(EventSource API), WebSocket
<br/>


#### 종단 간 이벤트 스트림 <small class="weak">End-to-end event streams</small>
사용자 입력 이벤트 스트림이나 서버 응답 스트림을 구독하는 방식으로 클라이언트 측 상태를 관리한다.

이는 구조적으로 이벤트 소싱과 비슷하다.

<br/>


#### 읽기도 이벤트다 <small class="weak">Reads are events too</small>

<br/>


#### 다중 파티션 데이터 처리 <small class="weak">Multi-partition data processing</small>
<br/>